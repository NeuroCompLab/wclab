---
title: "Unsupervised pretraining in biological neural networkssss"
description: |
  Unsupervised learning - exposure to stimuli without rewards - drives large changes in neural activity in visual cortex, particularly in higher order medial visual areas.
categories:
  - Vision
  - Thousands of neurons
  - Behavior
date: June 2025
author: Lin Zhong, Scott Baptista, Rachel Gattoni, Jon Arnold, Daniel Flickinger, Carsen Stringer<sup>â€ </sup>, Marius Pachitariu<sup>â€ </sup>
toc: false
image: images/zhong_cover.png
image-alt: unsupervised and supervised learning
---

<details>
  <summary><p style="font-size: smaller">Abstract</p></summary>
  <p style="font-size: smaller">
Representation learning in neural networks may be implemented with supervised or unsupervised algorithms, distinguished by the availability of instruction. In the sensory cortex, perceptual learning drives neural plasticity, but it is not known whether this is due to supervised or unsupervised learning. Here we recorded populations of up to 90,000 neurons simultaneously from the primary visual cortex (V1) and higher visual areas (HVAs) while mice learned multiple tasks, as well as during unrewarded exposure to the same stimuli. Similar to previous studies, we found that neural changes in task mice were correlated with their behavioural learning. However, the neural changes were mostly replicated in mice with unrewarded exposure, suggesting that the changes were in fact due to unsupervised learning. The neural plasticity was highest in the medial HVAs and obeyed visual, rather than spatial, learning rules. In task mice only, we found a ramping reward-prediction signal in anterior HVAs, potentially involved in supervised learning. Our neural results predict that unsupervised learning may accelerate subsequent task learning, a prediction that we validated with behavioural experiments.</p>
</details>

<a href="https://www.nature.com/articles/s41586-025-09180-y">paper</a> |
<a href="https://www.janelia.org/news/zoning-out-could-be-beneficial%E2%80%94and-may-actually-help-us-learn-faster">news article</a> |
<a href="https://doi.org/10.25378/janelia.28811129.v1">dataset</a> |
<a href="https://github.com/MouseLand/zhong-et-al-2025">code</a> |
<a href="https://www.biorxiv.org/content/10.1101/2024.02.25.581990v2">preprint</a> |
<hr>

Thread by Lin Zhong:

1. Simple question: How do we learn? 
Answer: From teachers (*supervised*). 

Sure! But we also learn a lot on our own (*unsupervised*), and so do our mice.
<p><video src='https://github.com/MouseLand/MouseLand.github.io/releases/download/v0.1/main_zhong.mp4' width="90%" loop="true" autoplay="autoplay" controls muted></video></p>

2. We developed a virtual reality (VR) task in which mice discriminated textures in order to get reward (supervised cohort) OR they just ran for FUN (unsupervised cohort).</p>
<img src='images/zhong_2.png' width="70%"></p>

3. Mice learned to discriminate textures by licking in the corridor with reward.</p>
<p><img src='images/zhong_3.png' width="70%"></p>

4. We recorded up to 90,000 neurons from the visual cortex during learning to try to understand the neural mechanism. Neural activities are visualized using our sorting algorithm Rastermap with behavioral annotations.</p>
<p><img src='https://github.com/MouseLand/MouseLand.github.io/releases/download/v0.1/rastermap_zhong.gif' width="90%"></p>

5. We found that the plasticity in medial visual areas was mediated by unsupervised learning.
<p><img src='images/zhong_5.png' width="80%"></p>

6. Mice correctly generalized the reward rule to new stimuli based on the visual similarities, behaviorally and neurally.</p>
<p><img src='images/zhong_6.png' width="90%"></p>

7. Mice learned to discriminate two very similar textures (leaf1 vs leaf2) by orthogonalizing them in the neural space</p>
<p><img src='images/zhong_7.png' width="80%"></p>

8. Learning that only leaf1 was rewarded results in de-orthogonalization of another new leaf (leaf3).</p>
<p><img src='images/zhong_8.png' width="70%"></p>

9. Question: Wait! We donâ€™t need supervised learning at all?
I will say no to my supervisor if that is true ðŸ™ƒ.

10. Our results suggest I should think twice before doing that: inside the anterior visual areas we found a representation only in the supervised learning task, which can predict the reward and was highly correlated with behavior.</p>
<p><img src='images/zhong_9.png' width="80%"></p>

11. Question: What does unsupervised learning do?
One possible answer is to pre-train our neural network for subsequent tasks.
Indeed, we show that mice learned much faster after experiencing unsupervised pretraining!</p>
<p><img src='images/zhong_10.png' width="50%"></p>

12. What is more, we found that V1 and lateral visual areas can encode novelty when seeing a new stimulus after learning. The novelty responses went away after mice got familiar with the new stimulus.</p>
<p><img src='images/zhong_11.png' width="80%"></p>

13. Our results show:
1) Most learning is through unsupervised learning, mediated by medial visual areas
2) Supervised learning may require anterior visual areas
3) A third stream (V1 + lateral) encodes novelty in both supervised and unsupervised learning

<br>
